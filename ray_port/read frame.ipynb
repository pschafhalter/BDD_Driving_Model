{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extracting Frames\n",
    "Extract frames using `ffmpeg`, e.g.\n",
    "```sh\n",
    "ffmpeg -i /home/ubuntu/samples-1k/videos/028b5d16-af6a6275.mov -r 15 \\\n",
    "            -qscale:v 10 -s 640*360 -threads 4 ~/Pictures//%04d.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named wrapper",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-63ec79eed85b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexample_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcStringIO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named wrapper"
     ]
    }
   ],
   "source": [
    "import wrapper\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.example import example_pb2\n",
    "from cStringIO import StringIO\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "a = wrapper.Wrapper(\"discrete_tcnn1\", \n",
    "            \"/data/yang/code/BDD_Driving_Model/data/discrete_tcnn1/model.ckpt-126001.bestmodel\",\n",
    "            20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Read a new frame: ', False)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function VideoCapture:\n",
      "\n",
      "VideoCapture(...)\n",
      "    VideoCapture() -> <VideoCapture object>\n",
      "    .   @brief Default constructor\n",
      "    .   @note In @ref videoio_c \"C API\", when you finished working with video, release CvCapture structure with\n",
      "    .   cvReleaseCapture(), or use Ptr\\<CvCapture\\> that calls cvReleaseCapture() automatically in the\n",
      "    .   destructor.\n",
      "    \n",
      "    \n",
      "    \n",
      "    VideoCapture(filename) -> <VideoCapture object>\n",
      "    .   @overload\n",
      "    .   @brief  Open video file or a capturing device or a IP video stream for video capturing\n",
      "    .   \n",
      "    .   Same as VideoCapture(const String& filename, int apiPreference) but using default Capture API backends\n",
      "    \n",
      "    \n",
      "    \n",
      "    VideoCapture(filename, apiPreference) -> <VideoCapture object>\n",
      "    .   @overload\n",
      "    .   @brief  Open video file or a capturing device or a IP video stream for video capturing with API Preference\n",
      "    .   \n",
      "    .   @param filename it can be:\n",
      "    .   - name of video file (eg. `video.avi`)\n",
      "    .   - or image sequence (eg. `img_%02d.jpg`, which will read samples like `img_00.jpg, img_01.jpg, img_02.jpg, ...`)\n",
      "    .   - or URL of video stream (eg. `protocol://host:port/script_name?script_params|auth`).\n",
      "    .   Note that each video stream or IP camera feed has its own URL scheme. Please refer to the\n",
      "    .   documentation of source stream to know the right URL.\n",
      "    .   @param apiPreference preferred Capture API backends to use. Can be used to enforce a specific reader\n",
      "    .   implementation if multiple are available: e.g. cv::CAP_FFMPEG or cv::CAP_IMAGES or cv::CAP_DSHOW.\n",
      "    .   @sa The list of supported API backends cv::VideoCaptureAPIs\n",
      "    \n",
      "    \n",
      "    \n",
      "    VideoCapture(index) -> <VideoCapture object>\n",
      "    .   @overload\n",
      "    .   @brief  Open a camera for video capturing\n",
      "    .   \n",
      "    .   @param index camera_id + domain_offset (CAP_*) id of the video capturing device to open. To open default camera using default backend just pass 0.\n",
      "    .   Use a `domain_offset` to enforce a specific reader implementation if multiple are available like cv::CAP_FFMPEG or cv::CAP_IMAGES or cv::CAP_DSHOW.\n",
      "    .   e.g. to open Camera 1 using the MS Media Foundation API use `index = 1 + cv::CAP_MSMF`\n",
      "    .   \n",
      "    .   @sa The list of supported API backends cv::VideoCaptureAPIs\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
